# Classifica√ß√£o de Imagens: Gatos vs. Cachorros com Transfer Learning e Fine-Tuning

Este projeto demonstra a constru√ß√£o de um classificador de imagens de aprendizado profundo para distinguir entre gatos e cachorros. A abordagem utiliza **Transfer Learning** e **Fine-Tuning** sobre a arquitetura VGG16, adaptada para processar imagens em escala de cinza.

O pipeline completo, desde o download e limpeza dos dados at√© o treinamento e avalia√ß√£o do modelo, est√° implementado no notebook `transfer_learning_fine_tuning.ipynb`.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/natomendes/transfer-learning-with-fine-tuning/blob/main/transfer_learning_fine_tuning.ipynb)

---

## üìú Vis√£o Geral

O objetivo √© classificar imagens com alta acur√°cia, aproveitando o conhecimento de um modelo pr√©-treinado (VGG16) na vasta base de dados ImageNet. O processo √© dividido em duas fases principais de treinamento:

1.  **Transfer Learning:** O modelo base (VGG16) √© "congelado", e apenas a cabe√ßa de classifica√ß√£o (camadas adicionadas no topo) √© treinada. Isso adapta o classificador para a nossa tarefa espec√≠fica sem alterar os extratores de caracter√≠sticas j√° aprendidos.
2.  **Fine-Tuning:** Algumas das camadas superiores do modelo base s√£o "descongeladas" e treinadas com uma taxa de aprendizado muito baixa. Isso ajusta sutilmente os extratores de caracter√≠sticas para se especializarem ainda mais no nosso dataset.

## üõ†Ô∏è Tecnologias Utilizadas

*   **TensorFlow & Keras:** Para a constru√ß√£o, treinamento e avalia√ß√£o do modelo de deep learning.
*   **VGG16:** Arquitetura de rede neural convolucional usada como base para o transfer learning.
*   **NumPy:** Para manipula√ß√£o de arrays e opera√ß√µes num√©ricas.
*   **Matplotlib & Seaborn:** Para visualiza√ß√£o de dados e resultados do treinamento.
*   **Scikit-learn:** Para gerar m√©tricas de avalia√ß√£o como o `classification_report`.
*   **Pillow (PIL):** Para manipula√ß√£o e verifica√ß√£o de imagens.

---

## üöÄ O Pipeline do Projeto

O fluxo de trabalho do projeto segue as seguintes etapas:

### 1. Prepara√ß√£o do Ambiente e Dados

*   **Download do Dataset:** O script baixa automaticamente o dataset "Cats and Dogs" da Microsoft.
*   **Limpeza de Dados:** Uma etapa crucial √© a verifica√ß√£o e remo√ß√£o de imagens corrompidas ou em formatos inesperados. O notebook implementa duas rotinas de limpeza para garantir a integridade dos dados que alimentam o modelo.
*   **Organiza√ß√£o:** As imagens s√£o divididas em diret√≥rios de `treino` e `valida√ß√£o`, mantendo a estrutura esperada pelo Keras (`train/cats`, `train/dogs`, etc.).

### 2. Cria√ß√£o do Modelo com Transfer Learning

*   **Adapta√ß√£o para Escala de Cinza:** Embora o VGG16 tenha sido treinado com imagens coloridas (3 canais), este projeto o adapta para aceitar imagens em escala de cinza (1 canal). Isso √© feito modificando a primeira camada convolucional e ajustando seus pesos (calculando a m√©dia dos pesos dos 3 canais originais).
*   **Congelamento do Modelo Base:** A base VGG16 √© congelada (`trainable = False`) para a primeira fase de treinamento.
*   **Adi√ß√£o da Cabe√ßa de Classifica√ß√£o:** Camadas `GlobalAveragePooling2D`, `Dropout` e `Dense` s√£o adicionadas no topo do modelo base para realizar a classifica√ß√£o final.

### 3. Treinamento em Duas Fases

O treinamento √© estrategicamente dividido para maximizar a performance:

*   **Fase 1 (Transfer Learning):** O modelo √© treinado por algumas √©pocas com o modelo base congelado. O objetivo √© treinar apenas o classificador adicionado.
*   **Fase 2 (Fine-Tuning):** As √∫ltimas 4 camadas do VGG16 s√£o descongeladas, e o modelo √© treinado novamente com uma **taxa de aprendizado muito baixa** (`learning_rate / 10`). Isso permite que os extratores de caracter√≠sticas mais complexos se ajustem ao nosso dataset espec√≠fico sem o risco de "esquecer" o que aprenderam com o ImageNet.

### 4. Callbacks e Otimiza√ß√µes

*   **EarlyStopping:** Interrompe o treinamento se a perda no conjunto de valida√ß√£o n√£o melhorar, evitando overfitting.
*   **ReduceLROnPlateau:** Reduz a taxa de aprendizado automaticamente se o treinamento estagnar.
*   **tf.data.Dataset:** O pipeline de dados √© otimizada com `.cache()` e `.prefetch()` para garantir que a GPU n√£o fique ociosa esperando por dados.

---

## üìä Resultados

O modelo atinge uma alta acur√°cia no conjunto de valida√ß√£o, demonstrando a efic√°cia da abordagem de transfer learning e fine-tuning. Os gr√°ficos de treinamento mostram a evolu√ß√£o da acur√°cia e da perda ao longo das duas fases.

**Exemplo de Gr√°fico de Treinamento:**

  <!-- Placeholder for an actual training graph image -->

A linha vermelha pontilhada indica o in√≠cio da fase de fine-tuning, onde geralmente observamos uma melhoria adicional na performance do modelo.

---

## ‚öôÔ∏è Como Executar

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/natomendes/transfer-learning-with-fine-tuning.git
    cd transfer-learning-with-fine-tuning
    ```

2.  **Instale as depend√™ncias:**
    √â recomendado criar um ambiente virtual.
    ```bash
    pip install tensorflow numpy matplotlib requests scikit-learn seaborn pillow
    ```

3.  **Execute o Notebook:**
    Abra e execute o `transfer_learning_fine_tuning.ipynb` em um ambiente como Jupyter Notebook, JupyterLab ou Google Colab.

    *   **Primeira Execu√ß√£o:** Descomente a linha `base_dir = download_and_extract_dataset()` para baixar e extrair os dados.
    *   **Execu√ß√µes Subsequentes:** Comente a linha de download e use `base_dir = 'PetImages'` para pular o download.

---

## üìÅ Estrutura de Arquivos

```
‚îú‚îÄ‚îÄ README.md                                     # Este arquivo
‚îî‚îÄ‚îÄ transfer_learning_fine_tuning.ipynb           # Notebook com todo o c√≥digo do projeto
